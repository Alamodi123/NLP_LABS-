{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM77+NTVJQTyj/RnPOHLTbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alamodi123/Alamodi123/blob/main/NLP_lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_UJ7THyr-DK",
        "outputId": "59076f4d-72a8-4abc-a3d2-f8d3aa523ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: The quick brown fox jumps over the lazy dog.\n",
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
            "  (VP jumps/VBZ (PP over/IN (NP the/DT lazy/JJ dog/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['The quick brown fox', 'the lazy dog']\n",
            "\n",
            "Sentence: A beautiful butterfly landed on the colorful flower.\n",
            "POS Tags: [('A', 'DT'), ('beautiful', 'JJ'), ('butterfly', 'NN'), ('landed', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('colorful', 'JJ'), ('flower', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP A/DT beautiful/JJ butterfly/NN)\n",
            "  (VP landed/VBD (PP on/IN (NP the/DT colorful/JJ flower/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['A beautiful butterfly', 'the colorful flower']\n",
            "\n",
            "Sentence: The experienced teacher explained the complex concept clearly.\n",
            "POS Tags: [('The', 'DT'), ('experienced', 'JJ'), ('teacher', 'NN'), ('explained', 'VBD'), ('the', 'DT'), ('complex', 'JJ'), ('concept', 'NN'), ('clearly', 'RB'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT experienced/JJ teacher/NN)\n",
            "  (VP explained/VBD (NP the/DT complex/JJ concept/NN))\n",
            "  clearly/RB\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['The experienced teacher', 'the complex concept']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Download required resources (run once)\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "def demo_phrase_chunking():\n",
        "    \"\"\"\n",
        "    Demonstrates basic noun phrase chunking using regular expressions\n",
        "    \"\"\"\n",
        "    sentences = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"A beautiful butterfly landed on the colorful flower.\",\n",
        "        \"The experienced teacher explained the complex concept clearly.\"\n",
        "    ]\n",
        "\n",
        "    # Define grammar for NP chunking\n",
        "    # NP: {<DT>?<JJ>*<NN.*>+} matches:\n",
        "    # - Optional determiner (DT): the, a, an\n",
        "    # - Zero or more adjectives (JJ)\n",
        "    # - One or more nouns (NN, NNS, NNP, NNPS)\n",
        "    grammar = r\"\"\"\n",
        "    NP: {<DT|PP\\$>?<JJ>*<NN.*>+}\n",
        "    PP: {<IN><NP>}\n",
        "    VP: {<VB.*><NP|PP|CLAUSE>+}\n",
        "    \"\"\"\n",
        "    # Create parser\n",
        "    cp = RegexpParser(grammar)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        print(f\"\\nSentence: {sentence}\")\n",
        "        # Tokenize and POS tag\n",
        "        tokens = word_tokenize(sentence)\n",
        "        pos_tags = pos_tag(tokens)\n",
        "        print(f\"POS Tags: {pos_tags}\")\n",
        "\n",
        "        # Parse\n",
        "        tree = cp.parse(pos_tags)\n",
        "        print(f\"Parse Tree:\\n{tree}\")\n",
        "\n",
        "        # Extract noun phrases\n",
        "        noun_phrases = []\n",
        "        for subtree in tree.subtrees():\n",
        "            if subtree.label() == 'NP':\n",
        "                noun_phrases.append(' '.join(word for word, tag in subtree.leaves()))\n",
        "        print(f\"Extracted Noun Phrases: {noun_phrases}\")\n",
        "\n",
        "# Run demo\n",
        "demo_phrase_chunking()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ChEid75KD4pw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "501458c2"
      },
      "source": [
        "## Phrase Chunking Demonstration\n",
        "\n",
        "This code cell demonstrates **Phrase Chunking**, a fundamental technique in Natural Language Processing (NLP) for identifying and grouping grammatically related words into meaningful phrases.\n",
        "\n",
        "### What is Phrase Chunking?\n",
        "Phrase chunking (also known as shallow parsing) involves breaking down a sentence into non-overlapping, syntactically correlated parts (chunks). These chunks are typically Noun Phrases (NP), Verb Phrases (VP), and Prepositional Phrases (PP).\n",
        "\n",
        "### How it works (in this code):\n",
        "1.  **Tokenization**: The sentence is first split into individual words.\n",
        "2.  **Part-of-Speech (POS) Tagging**: Each word is assigned a grammatical category (e.g., noun, verb, adjective, determiner).\n",
        "3.  **Regular Expression Parser**: A set of regular expression rules (the `grammar` variable) defines patterns for how POS tags combine to form specific types of phrases.\n",
        "4.  **Parsing and Extraction**: The parser applies these rules to the POS-tagged sentence to identify and extract the defined phrases.\n",
        "\n",
        "### Why is Phrase Chunking Useful?\n",
        "Phrase chunking is a crucial step in NLP pipelines for several reasons:\n",
        "*   **Information Extraction**: Helps in identifying entities (like people, organizations, locations) and their relationships by isolating noun phrases.\n",
        "*   **Text Summarization**: Aids in understanding the core components of sentences, which can be used to select important information for summaries.\n",
        "*   **Question Answering**: Facilitates finding answers by matching phrases from questions to phrases in documents.\n",
        "*   **Machine Translation**: Provides structural information that can help in reordering words and phrases for better translation quality across languages.\n",
        "*   **Feature Engineering**: The extracted chunks can serve as powerful features for machine learning models in various NLP tasks like sentiment analysis or document classification.\n",
        "\n",
        "This demonstration provides a hands-on look at how these basic grammatical units can be automatically identified from raw text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a6f4d0b",
        "outputId": "7d323fcb-8b07-4bbc-f03d-f06654d891d4"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Note: NLTK resources are assumed to be downloaded from previous cells.\n",
        "\n",
        "def demo_phrase_chunking_original_sentences_vp_prp():\n",
        "    \"\"\"\n",
        "    Demonstrates noun, verb, and pronoun phrase chunking using regular expressions\n",
        "    with the *original* set of sentences.\n",
        "    \"\"\"\n",
        "    sentences = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"A beautiful butterfly landed on the colorful flower.\",\n",
        "        \"The experienced teacher explained the complex concept clearly.\"\n",
        "    ]\n",
        "\n",
        "    # Define grammar for NP, PRP_PH, PP, and VP chunking\n",
        "    # This grammar includes rules for Pronoun Phrases and Verb Phrases.\n",
        "    grammar = r\"\"\"\n",
        "    NP: {<DT|PP\\$>?<JJ>*<NN.*>+}\n",
        "    PRP_PH: {<PRP|PRP\\$>+}\n",
        "    PP: {<IN><NP>}\n",
        "    VP: {<VB.*><NP|PP|CLAUSE>+}\n",
        "    \"\"\"\n",
        "    # Create parser\n",
        "    cp = RegexpParser(grammar)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        print(f\"\\nSentence: {sentence}\")\n",
        "        # Tokenize and POS tag\n",
        "        tokens = word_tokenize(sentence)\n",
        "        pos_tags = pos_tag(tokens)\n",
        "        print(f\"POS Tags: {pos_tags}\")\n",
        "\n",
        "        # Parse\n",
        "        tree = cp.parse(pos_tags)\n",
        "        print(f\"Parse Tree:\\n{tree}\")\n",
        "\n",
        "        # Extract noun, verb, and pronoun phrases\n",
        "        noun_phrases = []\n",
        "        verb_phrases = []\n",
        "        pronoun_phrases = []\n",
        "        for subtree in tree.subtrees():\n",
        "            if subtree.label() == 'NP':\n",
        "                noun_phrases.append(' '.join(word for word, tag in subtree.leaves()))\n",
        "            elif subtree.label() == 'VP':\n",
        "                verb_phrases.append(' '.join(word for word, tag in subtree.leaves()))\n",
        "            elif subtree.label() == 'PRP_PH': # Check for the new Pronoun Phrase label\n",
        "                pronoun_phrases.append(' '.join(word for word, tag in subtree.leaves()))\n",
        "\n",
        "        print(f\"Extracted Noun Phrases: {noun_phrases}\")\n",
        "        print(f\"Extracted Verb Phrases: {verb_phrases}\")\n",
        "        print(f\"Extracted Pronoun Phrases: {pronoun_phrases}\")\n",
        "\n",
        "# Run the updated demo with original sentences\n",
        "demo_phrase_chunking_original_sentences_vp_prp()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: The quick brown fox jumps over the lazy dog.\n",
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
            "  (VP jumps/VBZ (PP over/IN (NP the/DT lazy/JJ dog/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['The quick brown fox', 'the lazy dog']\n",
            "Extracted Verb Phrases: ['jumps over the lazy dog']\n",
            "Extracted Pronoun Phrases: []\n",
            "\n",
            "Sentence: A beautiful butterfly landed on the colorful flower.\n",
            "POS Tags: [('A', 'DT'), ('beautiful', 'JJ'), ('butterfly', 'NN'), ('landed', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('colorful', 'JJ'), ('flower', 'NN'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP A/DT beautiful/JJ butterfly/NN)\n",
            "  (VP landed/VBD (PP on/IN (NP the/DT colorful/JJ flower/NN)))\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['A beautiful butterfly', 'the colorful flower']\n",
            "Extracted Verb Phrases: ['landed on the colorful flower']\n",
            "Extracted Pronoun Phrases: []\n",
            "\n",
            "Sentence: The experienced teacher explained the complex concept clearly.\n",
            "POS Tags: [('The', 'DT'), ('experienced', 'JJ'), ('teacher', 'NN'), ('explained', 'VBD'), ('the', 'DT'), ('complex', 'JJ'), ('concept', 'NN'), ('clearly', 'RB'), ('.', '.')]\n",
            "Parse Tree:\n",
            "(S\n",
            "  (NP The/DT experienced/JJ teacher/NN)\n",
            "  (VP explained/VBD (NP the/DT complex/JJ concept/NN))\n",
            "  clearly/RB\n",
            "  ./.)\n",
            "Extracted Noun Phrases: ['The experienced teacher', 'the complex concept']\n",
            "Extracted Verb Phrases: ['explained the complex concept']\n",
            "Extracted Pronoun Phrases: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thw code above is just printed the verb phrase and the pronoun along side with the noun phrase**"
      ],
      "metadata": {
        "id": "tuIyyuczCrL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependent and Independent Clause Demo\n",
        "import spacy\n",
        "# Load English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def identify_clauses(text):\n",
        "    \"\"\"\n",
        "    Identify independent and dependent clauses in a sentence.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    print(f\"\\nSentence: {text}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Find the root (main verb of independent clause)\n",
        "    root = [token for token in doc if token.dep_ == \"ROOT\"][0]\n",
        "\n",
        "    # Independent clause\n",
        "    print(\"\\nINDEPENDENT CLAUSE (can stand alone):\")\n",
        "    print(f\" Main verb: {root.text}\")\n",
        "\n",
        "    # Get subject and object of main clause\n",
        "    independent_words = [root.text]\n",
        "\n",
        "    for child in root.children:\n",
        "        if child.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
        "            print(f\" Subject: {child.text}\")\n",
        "            independent_words.insert(0, child.text)\n",
        "        elif child.dep_ in [\"dobj\", \"attr\"]:\n",
        "            print(f\" Object: {child.text}\")\n",
        "            independent_words.append(child.text)\n",
        "\n",
        "    print(f\" Clause: {' '.join(independent_words)}\")\n",
        "\n",
        "    # Dependent clauses\n",
        "    dependent_labels = {\n",
        "        'advcl': 'Adverbial Clause (tells when, why, how)',\n",
        "        'ccomp': 'Complement Clause (completes the meaning)',\n",
        "        'xcomp': 'Complement Clause',\n",
        "        'relcl': 'Relative Clause (describes a noun)',\n",
        "        'acl': 'Clausal Modifier'\n",
        "    }\n",
        "\n",
        "    print(\"\\nDEPENDENT CLAUSES (cannot stand alone):\")\n",
        "    found_dependent = False\n",
        "\n",
        "    for token in doc:\n",
        "        if token.dep_ in dependent_labels:\n",
        "            found_dependent = True\n",
        "            clause_words = [t.text for t in token.subtree]\n",
        "\n",
        "            # Find the subordinating word\n",
        "            marker = \"\"\n",
        "            for t in token.subtree:\n",
        "                if t.dep_ == \"mark\":\n",
        "                    marker = t.text\n",
        "                    break\n",
        "\n",
        "            print(f\"\\n Type: {dependent_labels[token.dep_]}\")\n",
        "            if marker:\n",
        "                print(f\" Marker: {marker}\")\n",
        "            print(f\" Verb: {token.text}\")\n",
        "            print(f\" Clause: {' '.join(clause_words)}\")\n",
        "\n",
        "    if not found_dependent:\n",
        "        print(\" None found - This is a simple sentence\")\n",
        "\n",
        "    print()\n",
        "# Demo sentences\n",
        "print(\"=\"*70)\n",
        "print(\"DEPENDENT vs INDEPENDENT CLAUSE DEMONSTRATION\")\n",
        "print(\"=\"*70)\n",
        "sentences = [\n",
        "    # Simple sentence - only independent clause\n",
        "    \"The dog barks.\",\n",
        "\n",
        "    # Adverbial clause (dependent)\n",
        "    \"I stayed home because it was raining.\",\n",
        "\n",
        "    # Complement clause (dependent)\n",
        "    \"I believe that she is right.\",\n",
        "\n",
        "    # Relative clause (dependent)\n",
        "    \"The student who studied hard passed the exam.\",\n",
        "\n",
        "    # Multiple dependent clauses\n",
        "    \"She said that she would come when she finished her work.\",\n",
        "\n",
        "    # Complex sentence\n",
        "    \"Although it was difficult, we completed the project.\"\n",
        "]\n",
        "for sentence in sentences:\n",
        "    identify_clauses(sentence)\n",
        "    print(\"-\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXDBUyMsMjO",
        "outputId": "051ced37-8185-4270-a893-46cab11ba230"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DEPENDENT vs INDEPENDENT CLAUSE DEMONSTRATION\n",
            "======================================================================\n",
            "\n",
            "Sentence: The dog barks.\n",
            "======================================================================\n",
            "\n",
            "INDEPENDENT CLAUSE (can stand alone):\n",
            " Main verb: barks\n",
            " Subject: dog\n",
            " Clause: dog barks\n",
            "\n",
            "DEPENDENT CLAUSES (cannot stand alone):\n",
            " None found - This is a simple sentence\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence: I stayed home because it was raining.\n",
            "======================================================================\n",
            "\n",
            "INDEPENDENT CLAUSE (can stand alone):\n",
            " Main verb: stayed\n",
            " Subject: I\n",
            " Clause: I stayed\n",
            "\n",
            "DEPENDENT CLAUSES (cannot stand alone):\n",
            "\n",
            " Type: Adverbial Clause (tells when, why, how)\n",
            " Marker: because\n",
            " Verb: raining\n",
            " Clause: because it was raining\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence: I believe that she is right.\n",
            "======================================================================\n",
            "\n",
            "INDEPENDENT CLAUSE (can stand alone):\n",
            " Main verb: believe\n",
            " Subject: I\n",
            " Clause: I believe\n",
            "\n",
            "DEPENDENT CLAUSES (cannot stand alone):\n",
            "\n",
            " Type: Complement Clause (completes the meaning)\n",
            " Marker: that\n",
            " Verb: is\n",
            " Clause: that she is right\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence: The student who studied hard passed the exam.\n",
            "======================================================================\n",
            "\n",
            "INDEPENDENT CLAUSE (can stand alone):\n",
            " Main verb: passed\n",
            " Subject: student\n",
            " Object: exam\n",
            " Clause: student passed exam\n",
            "\n",
            "DEPENDENT CLAUSES (cannot stand alone):\n",
            "\n",
            " Type: Relative Clause (describes a noun)\n",
            " Verb: studied\n",
            " Clause: who studied\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence: She said that she would come when she finished her work.\n",
            "======================================================================\n",
            "\n",
            "INDEPENDENT CLAUSE (can stand alone):\n",
            " Main verb: said\n",
            " Subject: She\n",
            " Clause: She said\n",
            "\n",
            "DEPENDENT CLAUSES (cannot stand alone):\n",
            "\n",
            " Type: Complement Clause (completes the meaning)\n",
            " Marker: that\n",
            " Verb: come\n",
            " Clause: that she would come when she finished her work\n",
            "\n",
            " Type: Adverbial Clause (tells when, why, how)\n",
            " Verb: finished\n",
            " Clause: when she finished her work\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Sentence: Although it was difficult, we completed the project.\n",
            "======================================================================\n",
            "\n",
            "INDEPENDENT CLAUSE (can stand alone):\n",
            " Main verb: completed\n",
            " Subject: we\n",
            " Object: project\n",
            " Clause: we completed project\n",
            "\n",
            "DEPENDENT CLAUSES (cannot stand alone):\n",
            "\n",
            " Type: Adverbial Clause (tells when, why, how)\n",
            " Marker: Although\n",
            " Verb: was\n",
            " Clause: Although it was difficult\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Summrization of the code's output**\n",
        "\n",
        "Breaking sentences into clauses is a critical step in NLP for several reasons, as it allows for a deeper and more structured understanding of text than just individual words or simple phrases.\n",
        "\n",
        "\n",
        "---\n",
        "Both phrases and clauses are groups of words, but their key difference lies in whether they contain a subject-verb pair:\n",
        "\n",
        "**Phrase** : A group of two or more words that functions as a single unit in a sentence.\n",
        "\n",
        "**Clause** :A group of words that contains both a subject and a verb.\n",
        "\n",
        "**In summary** : The presence of a subject-verb pair is the defining characteristic that elevates a group of words from a phrase to a clause. A phrase is a building block of a clause, while a clause is a building block of a sentence."
      ],
      "metadata": {
        "id": "uC9ck1FjAVJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hierachical Syntax Tree\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "# Example text\n",
        "sample_text = \"The quick brown fox jumps over the lazy dog\"\n",
        "# Tokenize and tag parts of speech\n",
        "tagged = pos_tag(word_tokenize(sample_text))\n",
        "# Define chunking patterns\n",
        "chunker = RegexpParser(\"\"\"\n",
        " NP: {<DT>?<JJ>*<NN.*>+} # Noun Phrases\n",
        "P: {<IN>} # Prepositions\n",
        "V: {<VB.*>} # Verbs\n",
        "PP: {<P><NP>} # Prepositional Phrases\n",
        "VP: {<V><NP|PP>*} # Verb Phrases\n",
        "\"\"\")\n",
        "# Parse and extract phrases\n",
        "output = chunker.parse(tagged)\n",
        "# Display results\n",
        "print(\"POS Tags:\")\n",
        "for word, tag in tagged:\n",
        "    print(f\" {word:10} -> {tag}\")\n",
        "print(\"\\nParsed Output:\")\n",
        "print(output)\n",
        "print(\"\\nTree Structure:\")\n",
        "output.pretty_print()\n",
        "print(\"\\nExtracted Phrases:\")\n",
        "for subtree in output.subtrees():\n",
        "    if subtree.label() != 'S':\n",
        "        phrase_text = ' '.join(word for word, tag in subtree.leaves())\n",
        "        print(f\"{subtree.label()}: {phrase_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F172Cep6y3xP",
        "outputId": "b3b3dd67-050f-444c-e365-4fe2cf0fff41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags:\n",
            " The        -> DT\n",
            " quick      -> JJ\n",
            " brown      -> NN\n",
            " fox        -> NN\n",
            " jumps      -> VBZ\n",
            " over       -> IN\n",
            " the        -> DT\n",
            " lazy       -> JJ\n",
            " dog        -> NN\n",
            "\n",
            "Parsed Output:\n",
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
            "  (VP (V jumps/VBZ) (PP (P over/IN) (NP the/DT lazy/JJ dog/NN))))\n",
            "\n",
            "Tree Structure:\n",
            "                                    S                                      \n",
            "           _________________________|_______________                        \n",
            "          |                                         VP                     \n",
            "          |                          _______________|_____                  \n",
            "          |                         |                     PP               \n",
            "          |                         |         ____________|_____            \n",
            "          NP                        V        P                  NP         \n",
            "   _______|________________         |        |       ___________|______     \n",
            "The/DT quick/JJ brown/NN fox/NN jumps/VBZ over/IN the/DT     lazy/JJ dog/NN\n",
            "\n",
            "\n",
            "Extracted Phrases:\n",
            "NP: The quick brown fox\n",
            "VP: jumps over the lazy dog\n",
            "V: jumps\n",
            "PP: over the lazy dog\n",
            "P: over\n",
            "NP: the lazy dog\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Key Differences and summrization of the code output**:\n",
        "\n",
        "**Phrases vs. Clauses**:\n",
        "\n",
        "A phrase is a group of words without a subject-verb pair (e.g., \"the quick fox\"), while a clause contains both a subject and a verb (e.g., \"the fox jumps\"). Clauses are fundamental in NLP for understanding complete thoughts and complex sentence structures.\n",
        "\n",
        "**Constituency vs. Dependency Trees**:\n",
        "\n",
        "Constituency trees group words into nested grammatical phrases (like Noun Phrases, Verb Phrases).\n",
        "Dependency trees show direct grammatical relationships between individual words (e.g., which word acts as the subject of a verb).\n",
        "\n",
        "**Importance of Trees in NLP**:\n",
        "\n",
        "Both types of hierarchical syntax trees are crucial because they provide the structural and relational understanding of sentences needed for advanced NLP tasks such as information extraction, machine translation, and question answering. They allow systems to interpret meaning beyond simple word sequences."
      ],
      "metadata": {
        "id": "g1iB_0Jt3Poy"
      }
    }
  ]
}